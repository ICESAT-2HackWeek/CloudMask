{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification of interesting VIIRS/MODIS files\n",
    "\n",
    "This notebook process a general bash file that retrieve VIIRS and MODIS images to return a new bash file with the images that mathches ICESat-2 data in a given temporal window.\n",
    "\n",
    "Prerequisites:\n",
    "- bash script file with the name of all the VIIRS/MODIS files in a given specific region (see https://search.earthdata.nasa.gov/search?m=-41.467241310846475!75.05859375!4!1!0!0%2C2)\n",
    "\n",
    "Imput:\n",
    "- Maximum temporal tolerance between ICESat-2 ann VIIRS/MOIDS retrievals\n",
    "- Spatial extent: this should be a subset of the spatial extent used to retrieve the scipt with the names of all the VIIRS/MODIS files\n",
    "\n",
    "Output:\n",
    "- Modified bash file with the names of the VIIRS/MODIS files that temporaly match with retrievals from ICESat-2\n",
    "\n",
    "\n",
    "\n",
    "In order to download the files, make the script an executable by running the line 'chmod 777 download.sh' from the command line. After that is complete, the file can be executed by typing './download.sh'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import icepyx as ipx\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "\n",
    "from utils import drainage_basin\n",
    "from utils_cloud import CLDMSK_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial extend for the ICESat-2 search \n",
    "# Observation: in case that the VIIRS file retrieve images in a different spatial extent, then we are no going to have matches, \n",
    "# independently of the window. \n",
    "basins_ids = [1.1, 1.2, 1.3, 1.4,\n",
    "              2.1, 2.2, \n",
    "              3.1, 3.2, 3.3, \n",
    "              4.1, 4.2, 4.3,\n",
    "              5.0,\n",
    "              6.1, 6.2,\n",
    "              7.1, 7.2, \n",
    "              8.1, 8.2]\n",
    "\n",
    "my_basins = basins_ids\n",
    "polygons = [drainage_basin(basin_id) for basin_id in my_basins ]\n",
    "poly_full = unary_union(polygons)\n",
    "poly_full_simplify = poly_full.simplify(tolerance=0.5)\n",
    "\n",
    "spatial_extent = list(poly_full_simplify.exterior.coords)\n",
    "\n",
    "# Temporal window in minutes\n",
    "minutes = 5\n",
    "hr = minutes / 60 \n",
    "# Maximim number of files we are interested in retrieve \n",
    "max_filtered = 100000000000\n",
    "\n",
    "\n",
    "# lenght of line if bash file with CLDMSK imagen name\n",
    "length_bash = 146\n",
    "\n",
    "# path with bash retrieval files\n",
    "#path_retrieve = \"data/VIIRS_bash/\"\n",
    "path_retrieve = \"data/Earthdata_scripts/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select your satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = \"VIIRS\"\n",
    "#sensor = \"MODIS-Aqua\"\n",
    "\n",
    "if sensor == \"VIIRS\":\n",
    "    \n",
    "    # name of the original bash file to retrieve the data\n",
    "    exe_old = \"CLDMSK-VIIRS-Greenland-2019.sh\"\n",
    "    # name of the output bash file \n",
    "    exe_new = \"CLDMSK-VIIRS-Greenland-2019-filtered-5min.sh\"\n",
    "    #lenght_bash = viirs_length_bash\n",
    "    \n",
    "if sensor == \"MODIS-Aqua\":\n",
    "    \n",
    "    exe_old = \"CLDMSK_L2_MODIS_Aqua-Greenland-2019.sh\"\n",
    "    exe_new = \"CLDMSK_L2_MODIS_Aqua-Greenland-2019-filtered.sh\"    \n",
    "    #lenght_bash = modis_aqua_length_bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> There are a total of 2 files founded out of 100 file names.\n",
      ">>> There are a total of 10 files founded out of 200 file names.\n",
      ">>> There are a total of 11 files founded out of 300 file names.\n",
      ">>> There are a total of 15 files founded out of 400 file names.\n",
      ">>> There are a total of 21 files founded out of 500 file names.\n",
      ">>> There are a total of 26 files founded out of 600 file names.\n",
      ">>> There are a total of 30 files founded out of 700 file names.\n",
      ">>> There are a total of 39 files founded out of 800 file names.\n",
      ">>> There are a total of 40 files founded out of 900 file names.\n",
      ">>> There are a total of 45 files founded out of 1000 file names.\n",
      ">>> There are a total of 47 files founded out of 1100 file names.\n",
      ">>> There are a total of 53 files founded out of 1200 file names.\n",
      ">>> There are a total of 64 files founded out of 1300 file names.\n",
      ">>> There are a total of 65 files founded out of 1400 file names.\n",
      ">>> There are a total of 73 files founded out of 1500 file names.\n",
      ">>> There are a total of 74 files founded out of 1600 file names.\n",
      ">>> There are a total of 76 files founded out of 1700 file names.\n",
      ">>> There are a total of 88 files founded out of 1800 file names.\n",
      ">>> There are a total of 90 files founded out of 1900 file names.\n",
      ">>> There are a total of 92 files founded out of 2000 file names.\n",
      ">>> There are a total of 100 files founded out of 2100 file names.\n",
      ">>> There are a total of 103 files founded out of 2200 file names.\n",
      ">>> There are a total of 107 files founded out of 2300 file names.\n",
      ">>> There are a total of 119 files founded out of 2400 file names.\n",
      ">>> There are a total of 124 files founded out of 2500 file names.\n",
      ">>> There are a total of 134 files founded out of 2600 file names.\n",
      ">>> There are a total of 137 files founded out of 2700 file names.\n",
      ">>> There are a total of 140 files founded out of 2800 file names.\n",
      ">>> There are a total of 147 files founded out of 2900 file names.\n",
      ">>> There are a total of 152 files founded out of 3000 file names.\n",
      ">>> There are a total of 157 files founded out of 3100 file names.\n",
      ">>> There are a total of 164 files founded out of 3200 file names.\n",
      ">>> There are a total of 175 files founded out of 3300 file names.\n",
      ">>> There are a total of 180 files founded out of 3400 file names.\n",
      ">>> There are a total of 181 files founded out of 3500 file names.\n",
      ">>> There are a total of 191 files founded out of 3600 file names.\n",
      ">>> There are a total of 197 files founded out of 3700 file names.\n",
      ">>> There are a total of 210 files founded out of 3800 file names.\n",
      ">>> There are a total of 215 files founded out of 3900 file names.\n",
      ">>> There are a total of 221 files founded out of 4000 file names.\n",
      ">>> There are a total of 230 files founded out of 4100 file names.\n",
      ">>> There are a total of 234 files founded out of 4200 file names.\n",
      ">>> There are a total of 246 files founded out of 4300 file names.\n",
      ">>> There are a total of 248 files founded out of 4400 file names.\n",
      ">>> There are a total of 256 files founded out of 4500 file names.\n",
      ">>> There are a total of 264 files founded out of 4600 file names.\n",
      ">>> There are a total of 272 files founded out of 4700 file names.\n",
      ">>> There are a total of 281 files founded out of 4800 file names.\n",
      ">>> There are a total of 287 files founded out of 4900 file names.\n",
      ">>> There are a total of 292 files founded out of 5000 file names.\n",
      ">>> There are a total of 304 files founded out of 5100 file names.\n",
      ">>> There are a total of 311 files founded out of 5200 file names.\n",
      ">>> There are a total of 311 files founded out of 5300 file names.\n",
      ">>> There are a total of 321 files founded out of 5400 file names.\n",
      ">>> There are a total of 324 files founded out of 5500 file names.\n",
      ">>> There are a total of 324 files founded out of 5600 file names.\n",
      ">>> There are a total of 336 files founded out of 5700 file names.\n",
      ">>> There are a total of 347 files founded out of 5800 file names.\n",
      ">>> There are a total of 357 files founded out of 5900 file names.\n",
      ">>> There are a total of 358 files founded out of 6000 file names.\n",
      ">>> There are a total of 371 files founded out of 6100 file names.\n",
      ">>> There are a total of 381 files founded out of 6200 file names.\n",
      ">>> There are a total of 382 files founded out of 6300 file names.\n",
      ">>> There are a total of 394 files founded out of 6400 file names.\n",
      ">>> There are a total of 404 files founded out of 6500 file names.\n",
      ">>> There are a total of 404 files founded out of 6600 file names.\n",
      ">>> There are a total of 415 files founded out of 6700 file names.\n",
      ">>> There are a total of 426 files founded out of 6800 file names.\n",
      ">>> There are a total of 426 files founded out of 6900 file names.\n",
      ">>> There are a total of 426 files founded out of 7000 file names.\n",
      ">>> There are a total of 426 files founded out of 7100 file names.\n",
      ">>> There are a total of 428 files founded out of 7200 file names.\n",
      ">>> There are a total of 436 files founded out of 7300 file names.\n",
      ">>> There are a total of 449 files founded out of 7400 file names.\n",
      ">>> There are a total of 452 files founded out of 7500 file names.\n",
      ">>> There are a total of 462 files founded out of 7600 file names.\n",
      ">>> There are a total of 471 files founded out of 7700 file names.\n",
      ">>> There are a total of 479 files founded out of 7800 file names.\n",
      ">>> There are a total of 481 files founded out of 7900 file names.\n",
      ">>> There are a total of 488 files founded out of 8000 file names.\n",
      ">>> There are a total of 494 files founded out of 8100 file names.\n",
      ">>> There are a total of 497 files founded out of 8200 file names.\n",
      ">>> There are a total of 504 files founded out of 8300 file names.\n",
      ">>> There are a total of 510 files founded out of 8400 file names.\n",
      ">>> There are a total of 513 files founded out of 8500 file names.\n",
      ">>> There are a total of 521 files founded out of 8600 file names.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "file = open(path_retrieve + exe_old, 'r')\n",
    "new_file = open(path_retrieve + exe_new, 'x')\n",
    "\n",
    "#viirs_names = []\n",
    "\n",
    "counter = 0\n",
    "counter_filtered = 0\n",
    "\n",
    "for line in file:\n",
    "    \n",
    "    #print(line)\n",
    "    \n",
    "    if (\"https://ladsweb.modaps.eosdis.nasa.gov\" in line) and (len(line) == length_bash):\n",
    "                \n",
    "        if counter_filtered < max_filtered:\n",
    " \n",
    "            cloud_file_name = line[:-1].split(\"/\")[-1]\n",
    "            cloud_time = CLDMSK_date(cloud_file_name)\n",
    "\n",
    "                \n",
    "            # Temporal search window for \n",
    "            start = cloud_time - pd.DateOffset(hours=hr)\n",
    "            end   = cloud_time + pd.DateOffset(hours=hr) + pd.DateOffset(minutes=6)\n",
    "            \n",
    "\n",
    "            start_date_str = start.strftime('%Y-%m-%d')\n",
    "            end_date_str   = end.strftime('%Y-%m-%d')\n",
    "            start_time_str = start.strftime('%H:%M:%S')\n",
    "            end_time_str   = end.strftime('%H:%M:%S')\n",
    "\n",
    "            try:\n",
    "\n",
    "                region_a = ipx.Query(\"ATL06\", spatial_extent, [start_date_str, end_date_str], start_time_str, end_time_str)\n",
    "                avail_granules = region_a.avail_granules(ids=True)\n",
    "\n",
    "                #viirs_names.append(Vfile)\n",
    "                #new_file.write(Vfile + \"\\n\") # add \\n\n",
    "                assert len(avail_granules) > 0\n",
    "                new_file.write(line)\n",
    "                counter_filtered += 1\n",
    "\n",
    "            except AssertionError:\n",
    "                None\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        if counter % 100 == 0:\n",
    "            print(\">>> There are a total of\", counter_filtered, \"files founded out of\", counter, \"file names.\")\n",
    "            \n",
    "        #break\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        new_file.write(line)\n",
    "        \n",
    "    \n",
    "new_file.close()\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cloudmaskenv]",
   "language": "python",
   "name": "conda-env-.conda-cloudmaskenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
